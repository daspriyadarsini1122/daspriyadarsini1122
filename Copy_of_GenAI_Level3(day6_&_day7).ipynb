{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyOCdkJbNOYZKl27pJaess",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daspriyadarsini1122/daspriyadarsini1122/blob/master/Copy_of_GenAI_Level3(day6_%26_day7).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Steps to find Softmax function**\n",
        "\n",
        "- Exponentiate every element of the output layer and sum results(around 181.73 in this case)\n",
        "- Take each element of the output layer, exponentiate it and divide by the sum obtained by the step1(exp(1.3)/181.37 = 3.67/181.37 = 0.02\n",
        "- Input layer is a straight forward neuron, there is no processing in it\n",
        "- The hidden layer is of two types i) Sigmoid & ii) Relu(Rectified linear unit)\n",
        "- The output layer is linear neuron or Softmax neuron.\n",
        "- In output layer the number of neurons is equal to number of features of the problem.\n",
        "-"
      ],
      "metadata": {
        "id": "jWEi52bj9oww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To implement the neural network the libraries are needed**\n",
        "- **Tensorflow :** Tensorflow is developed by Google Brain team for internal Google use in research & production.The initial version was released under the apache License 2.0 in september 2015.Google realeased the updated version of tensorflow named tensorflow 2.0 in september 2019.\n",
        "- Whether you are an expert, or a beginner , tensorflow is an end to end platform that makes it easy for you to build & deploy ML/Neural networks deep learning model.\n",
        "- An entire eco system to help you solve challenging, real world problems with machine learning.\n",
        "- The most important thing to realize about Tensorflow is that , for the most part the core is not written in python. It's written in a combination of highly optimized c++ and CUDA(NVDIA's language for programming GPU's)\n",
        "- Much of that happens in turn , by using Eigen ( a high performance c++ and CUDA numerical library and NVDIA's cuDNN ( a very optimized DNN library for NVDIA GPUs, for functions such as convolutions.\n",
        "- So, the problem which faced here is who wants to interact with Tensorflow must needs to interact with c++.\n",
        "- So to overcome this KERAs library came in.\n"
      ],
      "metadata": {
        "id": "Wc_u7ENc51QA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KERAS**\n",
        "\n",
        "- It's an open source deep learning framework, which is written in Python, provides a high level API for building and training neural networks.It is used to be user-friendly, modular & extensible making it an excellent choice for both beginners and experts in deep learning.\n",
        "- Keras was created by Francois chollet, a google AI researcher & was first reased in march 2015.It started as an independent open source deep learning library but later became an official part of Tensorflow.(tf.keras)\n",
        "- Deep learning for humans.\n",
        "- Keras is an API designed for human beings not machines. Keras follows best practices for reducing cognitive load.It offers consistent & simple APIs, it minimizes the number of user actions required for common use cases and it provides clear & actionable error messages.It also has extensive documentation & developer guides.\n",
        "-** Book** : Deep learning with Python Francois chollet"
      ],
      "metadata": {
        "id": "ZhB7PYs1HtK7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PyTorch evolution**\n",
        "\n",
        "- Initially inspired by Torch(an older deep learning framework written in LUA)\n",
        "- Grew rapidly with support from Meta(Facebook) and the open source community.\n",
        "- In 2022, Meta transferred Pytorch to the linux foundation,ensuring it's long term open source governance."
      ],
      "metadata": {
        "id": "RKZl7KnIVV6L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/enuguru/GenAI/blob/main/neural-networks/ann/multi_layer_perceptron_pima_indians.ipynb\n",
        "\n",
        "Dataset - https://raw.githubusercontent.com/enuguru/GenAI/refs/heads/main/neural-networks/ann/pima-indians-diabetes.csv"
      ],
      "metadata": {
        "id": "IZV-ygD7XgkT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is an Epoch**\n",
        "\n",
        "- the number of epochs is a hyperparameter that defines the number of times that the learning algorithm will work through the entire dataset.\n",
        "- One epoch means, each sample in the training dataset has an oppurtunity to update the internal model parameters. An epoch is comprised of one or more batches. For ex, as above : an epoch that has one batch is called the batch gradient descent learning algorithm.\n",
        "- You can think of a for loop, over the number of epochs where each loop proceeds over the training dataset. Withing this for loop, there is another nested for loop that iterates over each batch of samples , where each batch has a specified \"batch size\" number of the sample.\n",
        "- At the end of the batch, predictions are compared to the expected output variables and an error is calculated, From this error the update algorithm is used to improve the model e.g , move down along the error gradient.\n",
        "- A training dataset can be divided into one or more batches. When all training sample are used to create one batch, the learning algorithm is called stochastic gradient descent.When the batch size is more than one sample and less than the size of the training dataset, the learning algorithm is called mini-batch gradient descent."
      ],
      "metadata": {
        "id": "1Rdy212270lk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cost function, loss function & objective function**\n",
        "\n",
        "- The loss function is to capture the difference between the actual & predicted values for a single record where as cost functions aggregate the difference for the entire training dataset.\n",
        "- The most commonly used loss functions are Mean-squared error and Hinge loss.\n",
        "- For regression we use 3 loss functions.\n",
        "i) MSE(Mean Squared Error)\n",
        "ii) MAE(Mean Absolute Error)\n",
        "iii) RMSE(Root Mean Squared Error)\n",
        "iv) MBE(Mean Bias Error)\n",
        "v) HL(Huber Loss)\n",
        "- For Binary classification:\n",
        "i) Likelihood Loss(LHL)\n",
        "ii)Binary Cross Entropy(BCE)\n",
        "iii) Hing Loss & Squared Hing Loss(HL and SHL)\n",
        "- For Multinomial classification:\n",
        "i) Categorical Cross Entropy(CLE)\n",
        "ii) Kullback Leibler Divergence(KLD)"
      ],
      "metadata": {
        "id": "WkJaNp6zpx7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top LLMs**\n",
        "\n",
        "- Claude from Anthropic\n",
        "- Gemini from Google\n",
        "- GPT from OpenAI\n",
        "- Llama from facebook\n",
        "- Mistral\n",
        "- Deepseek"
      ],
      "metadata": {
        "id": "tDcUo92CrBp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hello World program in GenAI\n",
        "# https://github.com/enuguru/GenAI/blob/main/GenAI_Introduction/mistral_models_working.ipynb\n",
        "\n",
        "\n",
        "!pip uninstall mistralai -y\n",
        "!pip install mistralai==0.4.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtX3vAe8t3CA",
        "outputId": "908db8e2-cee9-4272-998d-d7c0e3e111c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping mistralai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting mistralai==0.4.2\n",
            "  Downloading mistralai-0.4.2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25 in /usr/local/lib/python3.12/dist-packages (from mistralai==0.4.2) (0.28.1)\n",
            "Collecting orjson<3.11,>=3.9.10 (from mistralai==0.4.2)\n",
            "  Downloading orjson-3.10.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mistralai==0.4.2) (2.11.10)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25->mistralai==0.4.2) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25->mistralai==0.4.2) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25->mistralai==0.4.2) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25->mistralai==0.4.2) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25->mistralai==0.4.2) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.5.2->mistralai==0.4.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.5.2->mistralai==0.4.2) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.5.2->mistralai==0.4.2) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.5.2->mistralai==0.4.2) (0.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.25->mistralai==0.4.2) (1.3.1)\n",
            "Downloading mistralai-0.4.2-py3-none-any.whl (20 kB)\n",
            "Downloading orjson-3.10.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: orjson, mistralai\n",
            "  Attempting uninstall: orjson\n",
            "    Found existing installation: orjson 3.11.3\n",
            "    Uninstalling orjson-3.11.3:\n",
            "      Successfully uninstalled orjson-3.11.3\n",
            "Successfully installed mistralai-0.4.2 orjson-3.10.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from mistralai.client import MistralClient\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get your API key from Colab secrets\n",
        "api_key = userdata.get('MISTRAL_API_KEY')\n",
        "\n",
        "# Initialize the new client\n",
        "client = MistralClient(api_key=api_key)\n",
        "# https://console.mistral.ai/api-keys\n",
        "# https://aistudio.google.com/\n",
        "\n",
        "models = client.list_models()\n",
        "\n",
        "print(\"Available Mistral AI models:\")\n",
        "for model in models.data:\n",
        "    print(model.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "2oxUhOaGt9iF",
        "outputId": "d75e441d-8742-4619-cc72-bd2960788f96"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret MISTRAL_API_KEY does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4286483783.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Get your API key from Colab secrets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MISTRAL_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Initialize the new client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret MISTRAL_API_KEY does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/enuguru/GenAI/blob/main/GenAI_Introduction/gemini_list_models_hello_world_04_02_2025.ipynb\n",
        "# http://huggungface.co/models ( to create API key)\n",
        "# Task - open ai, claude from anthropic, llama ( do the API call with simple prompt)"
      ],
      "metadata": {
        "id": "QJJ75s70u-rp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}